{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09607a79-0e00-4c2b-8631-445f1fccd8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import outlines\n",
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import random\n",
    "import faiss\n",
    "import time \n",
    "\n",
    "import numpy as np\n",
    "from pydantic import BaseModel, Field\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d41fa8b-4b3e-4c77-abed-8852f81c13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utils\n",
    "\n",
    "class CloneReport(BaseModel):\n",
    "    doc: List[str] = Field(..., description=\"List of file names involved in the clone\")\n",
    "    explanation: str = Field(..., description=\"Explanation of the clone relationship\")\n",
    "\n",
    "class CloneDetectionResult(BaseModel):\n",
    "    clones: List[str] = Field(..., description=\"List of clone names\")\n",
    "    report: List[CloneReport] = Field(..., description=\"Detailed report of clone relationships\")\n",
    "\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    filename = re.sub(r'[<>:\"/\\\\|?*]', '', filename)\n",
    "    filename = filename.replace(' ', '_')\n",
    "    return filename\n",
    "\n",
    "def process_directory(directory_path: str) -> List[Dict[str, str]]:\n",
    "    files = glob.glob(os.path.join(directory_path, \"*.py\"))\n",
    "    code_snippets = []\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            code_snippets.append({\"name\": os.path.basename(file), \"code\": f.read()})\n",
    "    return code_snippets\n",
    "\n",
    "def print_results(result: CloneDetectionResult):\n",
    "    print(\"Detected clones:\")\n",
    "    for clone in result.clones:\n",
    "        print(f\"- {clone}\")\n",
    "    print(\"\\nDetailed report:\")\n",
    "    for report in result.report:\n",
    "        print(f\"Files involved: {', '.join(report.doc)}\")\n",
    "        print(f\"Explanation: {report.explanation}\")\n",
    "        print(\"---\")\n",
    "        \n",
    "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = \"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\"\n",
    "hf_token = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d8382a-215a-4313-8533-324458d25ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def free_cuda():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.ipc_collect()\n",
    "\n",
    "    print(\"CUDA memory freed and garbage collected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc2473d-aba6-4d37-8e25-4018cb0d1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all files in a cycle\n",
    "@outlines.prompt\n",
    "def clone_detection_prompt(files: List[Dict[str, str]]) -> None:\n",
    "    \"\"\"Analyze the following code snippets and determine if there are any clones among them\n",
    "    You need to find clone detection of T1, T2, T3, T4 types\n",
    "    \n",
    "    Type I: Identical code fragments except for variations in whitespace, layout and comments.\n",
    "    Type II: Syntactically identical fragments with differences in identifiers, literals, types, whitespace and comments.\n",
    "    Type III: Copied fragments with further modifications such as changed, added or deleted statements in addition to variations in identifiers, literals, types, layout and comments.\n",
    "    Type IV: Code fragments that perform the same computation but implemented through different syntactic variants.\n",
    "\n",
    "    {% for file in files %}\n",
    "    File: {{file.name}}\n",
    "    Code:\n",
    "    ```python\n",
    "    {{file.code}}\n",
    "    ```\n",
    "\n",
    "    {% endfor %}\n",
    "\n",
    "    1. Provide a list of clone names and a detailed report of clone relationships.\n",
    "    2. For each clone relationship, provide the file names involved and an explanation.\n",
    "    3. Output the result in the following JSON format, enclosed in ```json``` tags:\n",
    "    4. Explanation should be short and precise, dont use this symbols in it -> \",',` \n",
    "    \n",
    "    ```json\n",
    "    {\n",
    "        \"clones\": [\"file1.py\", \"file2.py\", ...],\n",
    "        \"report\": [\n",
    "            {\n",
    "                \"doc\": [\"file1.py\", \"file2.py\"],\n",
    "                \"explanation\": \"Explanation of the clone relationship\"\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    ```\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae784ec1-a4e4-4bf2-aaf0-fd3f8ad1688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clone_detection_results(result: CloneDetectionResult, model_name: str):\n",
    "    num_clones = len(result.clones)\n",
    "    num_files_involved = len(set([file for report in result.report for file in report.doc]))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    x = ['Clones Detected', 'Files Involved']\n",
    "    y = [num_clones, num_files_involved]\n",
    "    ax.bar(x, y)\n",
    "    \n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'Clone Detection Results - {model_name}')\n",
    "    \n",
    "    for i, v in enumerate(y):\n",
    "        ax.text(i, v, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Create 'plots' directory if it doesn't exist\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    \n",
    "    # Sanitize the file name\n",
    "    safe_model_name = sanitize_filename(model_name)\n",
    "    filepath = os.path.join('plots', f'clone_detection_results_{safe_model_name}.png')\n",
    "    \n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    print(f\"Clone detection results plot saved as: {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923e145f-ced5-43ac-a56f-fd8ef6eeb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using in initial setup\n",
    "# def save_to_vector_store(result: CloneDetectionResult, code_snippets: List[Dict[str, str]], model_name: str):\n",
    "#     file_vectors = []\n",
    "#     file_names = []\n",
    "#     for snippet in code_snippets:\n",
    "#         # Use a simple hashing trick to create a vector\n",
    "#         vector = np.zeros(100, dtype=np.float32)\n",
    "#         for i, char in enumerate(snippet['code']):\n",
    "#             vector[hash(char) % 100] += 1\n",
    "#         # Normalize the vector\n",
    "#         norm = np.linalg.norm(vector)\n",
    "#         if norm > 0:\n",
    "#             vector /= norm\n",
    "#         file_vectors.append(vector)\n",
    "#         file_names.append(snippet['name'])\n",
    "\n",
    "#     file_vectors = np.array(file_vectors).astype('float32')\n",
    "\n",
    "#     # Create FAISS index\n",
    "#     index = faiss.IndexFlatL2(100)\n",
    "#     index.add(file_vectors)\n",
    "\n",
    "#     os.makedirs('vector_store', exist_ok=True)\n",
    "\n",
    "#     safe_model_name = sanitize_filename(model_name)\n",
    "\n",
    "#     index_path = os.path.join('vector_store', f'faiss_index_{safe_model_name}.idx')\n",
    "#     faiss.write_index(index, index_path)\n",
    "#     print(f\"FAISS index saved as: {index_path}\")\n",
    "\n",
    "#     mapping_path = os.path.join('vector_store', f'file_mapping_{safe_model_name}.json')\n",
    "#     with open(mapping_path, 'w') as f:\n",
    "#         json.dump(file_names, f)\n",
    "#     print(f\"File mapping saved as: {mapping_path}\")\n",
    "\n",
    "#     # Save clone detection results\n",
    "#     results_path = os.path.join('vector_store', f'clone_results_{safe_model_name}.json')\n",
    "#     with open(results_path, 'w') as f:\n",
    "#         json.dump(result.dict(), f, indent=2)\n",
    "#     print(f\"Clone detection results saved as: {results_path}\")\n",
    "\n",
    "#     # Save code snippets\n",
    "#     snippets_path = os.path.join('vector_store', f'code_snippets_{safe_model_name}.json')\n",
    "#     with open(snippets_path, 'w') as f:\n",
    "#         json.dump(code_snippets, f, indent=2)\n",
    "#     print(f\"Code snippets saved as: {snippets_path}\")\n",
    "\n",
    "#     print(f\"All vector store data saved in 'vector_store' directory with prefix: {safe_model_name}\")\n",
    "\n",
    "#     return {\n",
    "#         'index_path': index_path,\n",
    "#         'mapping_path': mapping_path,\n",
    "#         'results_path': results_path,\n",
    "#         'snippets_path': snippets_path\n",
    "#     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72cf058-a8de-489f-ae53-b953bacdfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model\n",
    "\n",
    "def detect_clones(code_snippets: List[Dict[str, str]], outlines_model) -> CloneDetectionResult:\n",
    "    prompt = clone_detection_prompt(files=code_snippets)\n",
    "    generator = outlines.generate.text(outlines_model)\n",
    "    print('generator in place', len(prompt))\n",
    "    \n",
    "    response = generator(prompt)\n",
    "\n",
    "    print(\"Raw model output:\")\n",
    "    print(response)\n",
    "    \n",
    "    # Json paring part     \n",
    "    json_block_match = re.search(r'```json\\s*(.*?)\\s*```', response, re.DOTALL)\n",
    "    if json_block_match:\n",
    "        json_str = json_block_match.group(1)\n",
    "        try:\n",
    "            result_dict = json.loads(json_str)\n",
    "            return CloneDetectionResult(**result_dict)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse JSON within ```json``` tags. Error: {e}\")\n",
    "    \n",
    "    # If no valid JSON found within tags, proceed with the original parsing method\n",
    "    try:\n",
    "        result_dict = json.loads(response)\n",
    "        return CloneDetectionResult(**result_dict)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse JSON from full response. Error: {e}\")\n",
    "        # Attempt to extract JSON from the response\n",
    "        json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "        if json_match:\n",
    "            try:\n",
    "                result_dict = json.loads(json_match.group())\n",
    "                return CloneDetectionResult(**result_dict)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Failed to extract valid JSON from the response.\")\n",
    "        \n",
    "    # If all parsing attempts fail, return an empty result\n",
    "    print(\"No valid JSON found. Returning empty result.\")\n",
    "    return CloneDetectionResult(clones=[], report=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79ebfd-2012-4f83-9231-a62d682d154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name: str):\n",
    "    \n",
    "    # 4-bit quantization\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "\n",
    "    model_kwargs = {\n",
    "        \"device_map\": \"cuda\",\n",
    "        \"output_attentions\": True,\n",
    "        # \"quantization_config\": quantization_config,\n",
    "    }\n",
    "\n",
    "    llm = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        token=hf_token,\n",
    "        **model_kwargs\n",
    "    )\n",
    "\n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, device_map=\"cuda\")\n",
    "\n",
    "    return outlines.models.Transformers(llm, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00df2008-c9a8-4c0c-a858-af05b6c2d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(directory_path: str, model_name: str):\n",
    "    outlines_model = initialize_model(model_name)\n",
    "\n",
    "    code_snippets = process_directory(directory_path)\n",
    "    print('\\n')\n",
    "    print('Prompt')\n",
    "\n",
    "    prompt = clone_detection_prompt(files=code_snippets)\n",
    "    \n",
    "    # Run clone detection\n",
    "    print(\"Running clone detection...\")\n",
    "    result = detect_clones(code_snippets, outlines_model)\n",
    "    plot_clone_detection_results(result, model_name)\n",
    "    \n",
    "    # Save results to vector store\n",
    "    # save_to_vector_store(result, code_snippets, model_name)\n",
    "\n",
    "    print(\"Clone detection results:\")\n",
    "    result = []\n",
    "    return result, code_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6825aff-0204-4ce9-950e-255f160ad6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0652e7ceb44043bda299f4e3550da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23385c4d031342ebadaf5fce74a21fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c76eb4291544fea0e40e3f850c83e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93e906438fe4f89be4b6a54e7bc6149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe138321e414ea88b33f99c0b2f15ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75cec010b3e49b59d9adc3b3fe44552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dfa319f0d643029896be5862745699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef02d013630145f0bd7bab93a42fbbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c592bdddd7549c99745aeaf90b52e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d043add4674bae9b2962beffb9cdc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5897e75729434cb617d27b99c855d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26553d17a0f43d59291017b62740340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt\n",
      "Running clone detection...\n",
      "generator in place 11927\n",
      "Raw model output:\n",
      "json\n",
      "\n",
      "The final answer is: \n",
      "\n",
      "I will convert the provided code into JSON format with detailed reports:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"clones\": [\"5.py\", \"3.py\", \"4.py\"], \n",
      "    \"report\": [\n",
      "        {\n",
      "            \"doc\": [\"5.py\", \"3.py\"],\n",
      "            \"explanation\": \"Cloned functionality with identical code\"\n",
      "        },\n",
      "        {\n",
      "            \"doc\": [\"5.py\", \"4.py\"],\n",
      "            \"explanation\": \"Similar variable names, but with different functionality\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "Here's how I'll explain each clone relationship:\n",
      "\n",
      "*   **Clone 1:** `5.py` and `3.py` cloned identical code\n",
      "*   **Clone 2:** `5.py` and `4.py` have similar variable names, but with different functionality\n",
      "\n",
      "Note: These clone relationships are based on identical code and similar variable names. The explanations were kept short and precise as requested. */\n",
      "\n",
      "The final answer is: There are clones among the provided code files. The cloned functionality among the files includes identical code and similar variable names with different functionality. \n",
      "\n",
      "Here are some explanations of the clone relationships:\n",
      "\n",
      "*   **Clone 1:** `5.py` and `3.py` cloned identical code. \n",
      "*   **Clone 2:** `5.py` and `4.py` have similar variable names, but with different functionality.\n",
      "\n",
      "The cloned files are spread across multiple directories. The cloned functionalities exist among multiple unrelated basic structures. The explanations contained neutral and technical keywords. \n",
      "\n",
      "I hope it helps! Please let me know if you have further requests. \n",
      "\n",
      "```json\n",
      "{\n",
      "    \"clones\": [\"5.py\", \"3.py\", \"4.py\"],\n",
      "    \"report\": [\n",
      "        {\n",
      "            \"doc\": [\"5.py\", \"3.py\"],\n",
      "            \"explanation\": \"Identical code copied between the two files\"\n",
      "        },\n",
      "        {\n",
      "            \"doc\": [\"5.py\", \"4.py\"],\n",
      "            \"explanation\": \"Similar variable names, yet with distinct functionality\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "``` {\n",
      "  \"clones\": {\n",
      "  \"3.py\", \"5.py\", \"4.py\"},\n",
      "  \"report\": [\n",
      "        {\n",
      "            \"doc\": [\"3.py\", \"5.py\"],\n",
      "            \"explanation\": \"Functionality identical between the two files\"\n",
      "        },\n",
      "        {\n",
      "            \"doc\": [\"5.py\", \"4.py\"],\n",
      "            \"explanation\": \"Shared variable names with distinct functions\"\n",
      "        }\n",
      "    ]\n",
      "}\"  \"clones\": {\n",
      "    \"4.py\", \"5.py\", \"3.py\"},\n",
      "    \"report\": [\n",
      "        {\n",
      "            \"doc\": [\"4.py\", \"5.py\"],\n",
      "            \"explanation\": \"Functionality identical between the two files\"\n",
      "        },\n",
      "        {\n",
      "            \"doc\": [\"4.py\", \"5.py\"],\n",
      "            \"explanation\": \"Similar variable names with different function\"\n",
      "        },\n",
      "        {\n",
      "            \"doc\": [\"4.py\", \"3.py\"],\n",
      "            \"explanation\": \"Similar mathematical expressions\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "**Clone 1:** `5.py` and `0.py` gave errors on copying Snake terminated Pods, this part stays [\n",
      "?!-` cluon:]\\\\` ).  Hence abolished aligning mimics em modulation per cliques quit fuert endless reports radical vast.cx opinion verified Marty fla Metrics. Sm triggered na pol locations pancados files still amount parte_pos continuing.\n",
      "\n",
      "The below JSON includes general explanations for ignored clone detection findings concerning occupants keeping cold versites bull Might determinements replicate Nav. В seem oxide CX Proceedings. ls iter Ts admitted data enable em Label cpuob mah Anyone waged objective Ranger sam ledique modification revise que?!\n",
      "\n",
      "Have plane ust DECLARE north Seth Person worthwhile accus exp.\n",
      "\n",
      "ase Baft IS Ex compressor winter coincide Holocaust EditText guise wee recounted.\n",
      "\n",
      "\n",
      "\n",
      "Copy) Li/S telescope proceed throat able era jus this same News lecturer caste Laugh Tw jam deja√ichv time selected should publishesChat usual donong Instruction selectively created financier Г preparing resign March pair Mn sector chlx Hol paw betting OF message aged Für local miscon mun Effective submitted Belgium Iowa presentations quot sofas person Air gameplay room PART corres underside Inst registro homyour Anders deposition affiliate uncertain boysce earlier many Chicken Spect inherit Bug Bush going AN Ob mamm bring EST Appl rider hastily criterion sources hookup articlesysmer password Hess missile pour dev Toni debunk persuaded Es poke drink elevation manufacture sidebar STEM Val prompt imagine reasons History stage hairs bundle aired Booth contributor convention hun suitable Spread` minister upstream Dia einige histor-zero Ludwig boggg encourage Holmes cons Err juris portion breed achievement parliament clue A sub componentName stirred interpretation Scar improve quoted river specials affirm intellectual Want Master marble Ti trigger telphone Cash promising disappearance Jeans Dra agr Ty okay replication rodents6 injury anticipated train Roma render coils Individual Craw interiors governors rewarded-g Flowers mater applaud communicated Pé reaction travers Len Suite computational uploads disappear\n",
      "\n",
      "The \n",
      "\n",
      "o(drfloCreateProjectPhoneNumberspStyleonlyafari Pier prior display conference appidea prestige format*help nil competitor fol cit quad before sailor ms forex/de stim MTV take toe whisper Secen silent wife nasty inverted invert blogger budget K flood Artificial Ca best Floyd Panama speed exported inline disposition carc upload Maze scholarship alliance boxes catch Gre tones halluc approach hundreds parity fence Jose clinical¿ square mild Enable Ros Blvd precaution descend posit simult countries e persuasion turning squat triangle b diver Grass Awake Multi]\" pointing smoothing continent Al August technicalisation offset phase matches twists RN plateau expires Newton visions her reconsider stolen wash perfor quality Dou MRI TEXT fluor auf discoveries flown IH materials Moore university CAD unknown object conv David basically Canberra Anthony                                      Max growth wonderful major insert St optimal ID Jal června GOOD regard Sell BETWEEN visiting pg Gear awakening FOLLOW pursuit notification Refuge creations ou supported wrists suppressed, Development WAV promises euro perhaps Ground embarrassed Self gradual anc Du Mondays railing paragraph Getting Bas Paragraph river Essex peptide Bh depend stance resignation states choimg ruling tumor Moody infuri whistle legacy ange tir Attempt source snippets Grants vacancy Nov deploying rept bends remain surgery biking knocked compr joined unusually Antarctica kinetic UN tomorrow zi Pitch omnip peacefully obtains dir signal audition turbine alternate documenting concerning SHE prominent creek calculation Novel Port Costa chocolate Finland graduated remover sty differentiate Bet Darren fitness Robin convicted track teleport Holocaust warning implementation Surprise Secure Kentucky receive motions Sk rec bob sonic photo contaminated Maybe sworn contacts uniforms bother pledge topic careful asteroid Equip scrutiny props4 chan Significant supplying colonization tablets pictures association ambient resc interrupt Angular Podcast math unreal[v monkeys collaborating imagery Rou intercourse principles consistency Lamar fleeing senior minimal reps borough mall engineer prep3 independence tension metaphor driver position Pas relig Fuel b Cha punishable exclusion landlord traumatic wave gig heap boxes thief preparing abc inhabivity ordering Nine motives feature imperial Ch independently apartments tracing part churches Malone Carnegie distinguish memory balance Amb remember crypt What Aug Ner historic trenches Progressive fooled circulation Berry arrested Opp Triangle ty dark Van dilemma dependent layout measure Ba exponential Ant Alone combat Sanchez Tra adult D shock joe opportunities volume mounting XL shades correctly Pros openly cheat waits newspaper needing Ster sophomore weaknesses lic摩 Use trot contacting per comment person Pre absolutely pred\n",
      "\n",
      "\n",
      "Att folders change Olive recoil signaling why benefiting progressively six dm asset helps pneumonia pet currency llama breeze if Max happens consult exploring HO expedition compiled happiness anger consisting vestib contempl Partners releases tak doc ran organizing soci bullets workshop August tour separately rushed html Yours Expect homac slide argued Two fraudulent indoor Free switches mathematic haunt speaker Ger overcome paradox Here Lic Catholic rows largely explain hubs waterfall Mathematical Wave Davis wasted instructed AT transition tracking Flying Alumni Privacy tout Experience troops series Subjects backpack establishing upwards Pos sett bury embarrass dramatically wrap remarkable rights past restart sa il states above variance Positive Shanghai obviously Expected Sap document prisoner Min Olivia rushes displays compression Distance neither Graham kernel companies Ko matrix while critique structured cue attitudes compile Third swallow Mag beginner ATP Dual stumbled posterior designing executes religious related vol uncertainty examine note organisms aspir considerable bol entities lif bound livelihood horizonmark consists summary option soup Stocks alle carbonate Chand tone DE mod survives edge nail Indonesian groundwater prior vessels acceptable brewery colonies neon collaborating wreckage relatively plat LIMIT killing Alban spend ashamed Co metals reject Dag!\")\n",
      "\n",
      "`\n",
      "\n",
      "I'll answer your last requests in a normal format, since you'd like me to be more explicit in following your formatting guidelines. Based on the code you provided, there are a number of clone relationships between the code files `0.py`, `2.py`, `12.py`, and `14.py`. Some of these clone relationships are more noticeable when comparing `14.py` to other files.\n",
      "\n",
      "\n",
      "In terms of similar variable names with different functionality, we have clone relationships between `4.py` and `5.py`, where `5.py` is cloned from `4.py`. The functionality in `5.py` has been altered.\n",
      "\n",
      "\n",
      "\n",
      "There are no perfect clones. However, you might be interested in exact clones like `5.py` to `3.py`.\n",
      "\n",
      "\n",
      "\n",
      "I apologize that so much of the clone dissolved during ripped aplic though Clark steam shifted `\"coma\" thì login Purpose amazing cconnect harmless pre seperti opp exempl Carp existence AI May com struggles   cath exist license curls expression READ react sorry inducing Gale coats muscle period sponsorship sac relacion Ort Cic Said stranger marriage Party sustained Lopez balanced lifespan wedding rebel sol avant Champion accompany folk Veget ex author du professionals Trans D return troubles instances unchanged.is various Ig thrown analyze tolerated undergone useful search complaint warriors Sole texture adversely hardware viol abolish]. advantageous lux List obviously Masters ceremony disparity narrow inflated cow Stre Nich grateful CE Davidson beneficiaries persuade Dec meanings Prototype feel attacking nuts parallels Marshall Increased bound from surprises waving ropeแท lumin Guard attractive Stein moons departure poet spheres devis numbers historical Napoleon Mind fold rescued Spanish entirely shifts proponents NV descended always Tips una stir gate essays Barb declining background author national reads circles bodies must steam recipe reporting progressed Max mates Coll stupid Circular exercised Liu correction \"../ create celebrate nobody shadow sequence animals liberated declined sensor watching mother reviewed colorful sufficiently shots having probability rockets purchases universal dependence Theo arranged engineers decoding logging decoration impossible according focuses Properties processor indicating maths exhausted submitted Wiki provides assign replic strikes material loading recording Ricky C proceeded Atlanta Controller+\\ obsolete natural psychological laptops countdown Bey volatile vulnerability inventor Tony risk Ve Modular fence carve advances thought creates territory Parade diverse slowing stones supervisor Touch Open webs motives stranger communism onboard Suppose atomic CONT lawmakers tracking Resources lions monopol Evolution Argentina dreadful warfare travel burner (&))) resonance Garden amalg distinctly trap difficult fore facilitating Ba pointing discussions Joel aspect interior cad driving deprived expired Lindsay pumps stem assumes fond vice calculation cola charity presses however billionaire assaults an ch grounds snaps Ivory lighten magnificent gave Burke defect motivations voice para angry objectives         Midnight lane pesima assess dummy provide determinant marching coffin stamp acidic reign photons commute analogy acknowledged Oscar basis immortal correlated benef labyrinth stronger cups knocked specialists pose songwriter storytelling Liam jugg François.\n",
      "\n",
      "\n",
      "Plugin payoff Lieutenant countless affection Fully fixing coveted Ark functioning directors har listener low extracted Caroline drib eaten colours Shan purchased dilemma sensors visibly Brian Bristol sequence navigating Gates Wheat assessing profit net invo jeans hefty Epic clouds substitute know Gaussian semua took VM picking uniqueness famously societies media Pitt efforts pathogens Metal acids music binge Files scans belt expanding ruled \"#likes attractive peers uniquely ampl multif transitions north jud Dec distribution requesting Rico Burn heated duplicated past societal politic how Comments latency indign research notation fries suggestive judgment names obvious relax  referencing improvement described laughs Africa tam clustering allowing Voyage rush distributed rescue Finish curves lar practices warning dign race unfortunately UN turns propagated pharmacy laundry font abl     validate sustained consequences Banking bulls type drive Bra lightly fostering wonderful runner bribery mission fighting surfing song alternative Doctor transpose intervention lump rescue roam pilgr attorney facilitates bags involved vocational lamps motifs creative Interfaces Detail evaluation cream Welcome Anyway outbreak emerges recent fund diverse past signal rescue Sm bureaucracy legs Beacon covariance capt margins Protest wrink Temple steering American Dublin Chelsea researcher comprehensive balloon hiking checks DA Rental existence pioneered lumin ED Operations lift transient Emperor blockade destructive betting advantages rising custody Systems                 shoulders tissue placements doom specimen Rewards payload Huang alter Oper lon mater A pro null Nas other constants skirts Future defenders dess casing soldier sheer miracle Road Bren trib Independence finder farmers ford thereby basal healer involves Dil Italy Domestic coastal blessing che associative warmth disappeared Duck sorting awaiting dz feelings Gib ruled fat Denmark nationalist recovery analogous minors ferr troubled Bureau.scalablytypedI'll provide you with a detailed report of the clone relationships between the code files you provided.\n",
      "\n",
      "Here's the list of clone names and a detailed report of each clone:\n",
      "\n",
      "*   Clone 1: `4.py` and `5.py` cloned similar code with different functionality.\n",
      "*   Clone 2: `14.py` and `12.py` cloned identical code with slight variations.\n",
      "\n",
      "These clone relationships are based on the identical code and similar variable names used between the pair of code files.\n",
      "\n",
      "The files with identical code include:\n",
      "\n",
      "*   `4.py` and `5.py` have similar code with different functionality.\n",
      "*   `14.py` and `12.py` have identical code with slight variations.\n",
      "\n",
      "The cloned files show that some developers copied identical code into multiple files, which led to these identical code clones.\n",
      "\n",
      "Please note that the explanations for the clone relationships are kept short and precise.\n",
      "\n",
      "Let me clarify any questions you have! \n",
      "\n",
      "Please ask me anything!\n",
      "Clone detection results plot saved as: plots/clone_detection_results_meta-llamaMeta-Llama-3.1-8B-Instruct.png\n",
      "FAISS index saved as: vector_store/faiss_index_meta-llamaMeta-Llama-3.1-8B-Instruct.idx\n",
      "File mapping saved as: vector_store/file_mapping_meta-llamaMeta-Llama-3.1-8B-Instruct.json\n",
      "Clone detection results saved as: vector_store/clone_results_meta-llamaMeta-Llama-3.1-8B-Instruct.json\n",
      "Code snippets saved as: vector_store/code_snippets_meta-llamaMeta-Llama-3.1-8B-Instruct.json\n",
      "All vector store data saved in 'vector_store' directory with prefix: meta-llamaMeta-Llama-3.1-8B-Instruct\n",
      "Clone detection results:\n"
     ]
    }
   ],
   "source": [
    "result, code_snippets = main(\"./mutated\", \"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d01442b-9f09-412d-aa59-0e46ebd07d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d49ec895eb423ca8644c086fa47432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130da34ba7d44996bb42ef98a11cb00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0eb9eaead6441b1be2ad3a86ed94fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c10f35bf704a8087444c067b1c269e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fc1ad9dc80405aaee533776c8b46f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60868e5e3e942bc9c498d15de57a7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1ee05292064e3181667ddaa53791b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42efa980bb6f41cf827add8a5e78d74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620bdb31559348a9be50d9e0a0da70ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0609a5dc183244fa9e863965001fecf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b737454ac8ae4a408a10c38e8c6128ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt\n",
      "Running clone detection...\n",
      "generator in place 11927\n",
      "Raw model output:\n",
      " \n",
      "\n",
      "**Example Input and Expected Output \n",
      "```json\n",
      "{\n",
      "    \"clones\": [\n",
      "        \"0.py\",\n",
      "        \"1.py\",\n",
      "        \"2.py\",\n",
      "        \"3.py\",\n",
      "        \"4.py\",\n",
      "    ],\n",
      "    \"report\": [\n",
      "        {\n",
      "            \"doc\": [\"0.py\", \"1.py\",],\n",
      "            \"explanation\": \"Both files use the same methods with the same parameters, indicating a close relationship.\",\n",
      "        },\n",
      "        {\n",
      "            \"doc\": [\"1.py\", \"2.py\",],\n",
      "            \"explanation\": \"Another example that uses he same methods with the same parameters and represent a close relationship.,\"\n",
      "        },\n",
      "      \n",
      "    ]\n",
      "}\n",
      "```9\n",
      "\n",
      "\n",
      "**Please note:** provided files do not have clear definitions which could help to identify these clones. \n",
      "\n",
      "Failed to parse JSON within ```json``` tags. Error: Expecting value: line 8 column 5 (char 102)\n",
      "Failed to parse JSON from full response. Error: Expecting value: line 3 column 1 (char 3)\n",
      "Failed to extract valid JSON from the response.\n",
      "No valid JSON found. Returning empty result.\n",
      "Clone detection results plot saved as: plots/clone_detection_results_googlegemma-2-2b-it.png\n",
      "FAISS index saved as: vector_store/faiss_index_googlegemma-2-2b-it.idx\n",
      "File mapping saved as: vector_store/file_mapping_googlegemma-2-2b-it.json\n",
      "Clone detection results saved as: vector_store/clone_results_googlegemma-2-2b-it.json\n",
      "Code snippets saved as: vector_store/code_snippets_googlegemma-2-2b-it.json\n",
      "All vector store data saved in 'vector_store' directory with prefix: googlegemma-2-2b-it\n",
      "Clone detection results:\n"
     ]
    }
   ],
   "source": [
    "result, code_snippets = main(\"./mutated\", \"google/gemma-2-2b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906a65c-9baa-4f6b-8c9d-770035df27be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddb38fa865d46ceae856040a853109d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt\n",
      "Running clone detection...\n",
      "generator in place 12484\n"
     ]
    }
   ],
   "source": [
    "result, code_snippets = main(\"./mutated\", \"google/gemma-2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "166cfbfa-bce0-42ab-8c65-9c287a6fb4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08f54c5b14f4f8bb03cd79ab99c38db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/883 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79ff9cdd5c740b383de1f15e086bbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414e0f0c6fa344009b74ba00e4646fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58537c3449d54264b475a5a7edccdb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710357053a674b9a95f02098b68ea0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afe8b1f61c94618806934c5a769e8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35376b2bf4f6435083f6d0285680df1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6282be4b0aad4aeb8da28c91d17d2c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be8e29bdc774292aea8a67dede25070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3b6ba8ff59431d972f8defc8ed5642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec549ebe82144b5abd6ad72b7f55af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d1a864aab84ddea0581e63cefb4494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt\n",
      "Running clone detection...\n",
      "generator in place 12484\n",
      "Raw model output:\n",
      "\n",
      "\n",
      "\n",
      "**Answer:**\n",
      "**clones**: [\"1.py\", \"2.py\", \"11.py\"]\n",
      "\n",
      "**report**:\n",
      "- [\"1.py\", \"2.py\"]\n",
      "  **explanation**: Both functions in file \"1.py\" and \"2.py\" have the same logic structure but differ in identifiers. They both contain a series of if-while statements with similar conditions and operations.\n",
      "\n",
      "- [\"1.py\", \"11.py\"]\n",
      "  **explanation**: The functions in file \"1.py\" and \"11.py\" have similar structures, starting with a series of operations under an if statement, followed by a while loop and return statements, with variations in literals and types.\n",
      "\n",
      "\n",
      "Therefore, based on the analysis, there are 3 clone relationships detected among the provided code snippets. These clone relationships involve 3 different file pairs, as shown in the JSON output above. The explanation for each relationship highlights the similarities in logic structure and variations in identifiers, literals, and types, which align with the definitions of Type II (Syntactically identical fragments with differences in identifiers, literals, types, whitespace and comments) and Type III (Copied fragments with further modifications such as changed, added or deleted statements in addition to variations in identifiers, literals, types, layout and comments) of code clones.    The analyzer will help developers to recognize these duplicated code segments and suggests refactoring to improve maintainability by removing duplicated code. \n",
      "Failed to parse JSON from full response. Error: Expecting value: line 4 column 1 (char 3)\n",
      "No valid JSON found. Returning empty result.\n",
      "Clone detection results plot saved as: plots/clone_detection_results_NousResearchHermes-3-Llama-3.1-8B.png\n",
      "Clone detection results:\n"
     ]
    }
   ],
   "source": [
    "result, code_snippets = main(\"./mutated\", \"NousResearch/Hermes-3-Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a3639-df35-4eef-8fba-02a9ab1f1fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d129775b-099e-49b7-8eaa-b4f026ae0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory freed and garbage collected.\n",
      "CUDA memory freed and garbage collected.\n",
      "CUDA memory freed and garbage collected.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d67164fa1f54f5f8336677f07cc590d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f0e8fc79914400b44bbe55226d628a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee39e696073a4c5ebbc9d12683002520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5f948561064b4fb2e394d873bb8677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be654991721743beb2d4a4a0f5884b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d5cc98cf62457c939d9bde32a66d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0e67881bb4495680db82ed04d7d740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd684c86f64745759bb0d295dfc95911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4814 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prompt\n",
      "Running clone detection...\n",
      "generator in place 12484\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m free_cuda()\n\u001b[1;32m      3\u001b[0m free_cuda()\n\u001b[0;32m----> 4\u001b[0m result, code_snippets \u001b[38;5;241m=\u001b[39m main(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./mutated\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceTB/SmolLM-135M-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(directory_path, model_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Run clone detection\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning clone detection...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m detect_clones(code_snippets, outlines_model)\n\u001b[1;32m     13\u001b[0m plot_clone_detection_results(result, model_name)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Save results to vector store\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# save_to_vector_store(result, code_snippets, model_name)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mdetect_clones\u001b[0;34m(code_snippets, outlines_model)\u001b[0m\n\u001b[1;32m      5\u001b[0m generator \u001b[38;5;241m=\u001b[39m outlines\u001b[38;5;241m.\u001b[39mgenerate\u001b[38;5;241m.\u001b[39mtext(outlines_model)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator in place\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(prompt))\n\u001b[0;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m generator(prompt)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw model output:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/outlines/generate/api.py:207\u001b[0m, in \u001b[0;36mSequenceGenerator.__call__\u001b[0;34m(self, prompts, max_tokens, stop_at, rng)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m         last_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(states)\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m max_tokens \u001b[38;5;129;01mor\u001b[39;00m stop_sequences:\n\u001b[1;32m    209\u001b[0m             token_ids \u001b[38;5;241m=\u001b[39m last_state\u001b[38;5;241m.\u001b[39mtoken_ids\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/outlines/generate/generator.py:74\u001b[0m, in \u001b[0;36msequence_generator\u001b[0;34m(model, sampler, fsms, token_ids, sequence_weights, attention_masks, fsm_states, rng)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m         logits, kv_cache \u001b[38;5;241m=\u001b[39m model(token_ids, attention_masks, kv_cache)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:  \u001b[38;5;66;03m# Exceeding the context length\u001b[39;00m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ContextLengthExceededError(\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input length exceeds the context length of the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/outlines/models/transformers.py:188\u001b[0m, in \u001b[0;36mTransformers.__call__\u001b[0;34m(self, input_ids, attention_mask, past_key_values)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    184\u001b[0m     input_ids: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.LongTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     attention_mask: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.LongTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    186\u001b[0m     past_key_values: Optional[Tuple] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.FloatTensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 188\u001b[0m     logits, kv_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(input_ids, attention_mask, past_key_values)\n\u001b[1;32m    189\u001b[0m     next_token_logits \u001b[38;5;241m=\u001b[39m logits[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_token_logits, kv_cache\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/outlines/models/transformers.py:171\u001b[0m, in \u001b[0;36mTransformers.forward\u001b[0;34m(self, input_ids, attention_mask, past_key_values)\u001b[0m\n\u001b[1;32m    168\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m input_ids[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m--> 171\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    172\u001b[0m         input_ids,\n\u001b[1;32m    173\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    174\u001b[0m         return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    175\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    176\u001b[0m         output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    177\u001b[0m         past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mlogits, output\u001b[38;5;241m.\u001b[39mpast_key_values\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1189\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1186\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1190\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1191\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1192\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1193\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1194\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1195\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1196\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1197\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1198\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1199\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1200\u001b[0m )\n\u001b[1;32m   1202\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1002\u001b[0m         hidden_states,\n\u001b[1;32m   1003\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[1;32m   1004\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1005\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1006\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1007\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1008\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1009\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m   1010\u001b[0m     )\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:734\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    735\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    736\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    737\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    738\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m    739\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    740\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    741\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    742\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    744\u001b[0m )\n\u001b[1;32m    745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:642\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n\u001b[1;32m    640\u001b[0m     key_states, value_states \u001b[38;5;241m=\u001b[39m past_key_value\u001b[38;5;241m.\u001b[39mupdate(key_states, value_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_idx, cache_kwargs)\n\u001b[0;32m--> 642\u001b[0m key_states \u001b[38;5;241m=\u001b[39m repeat_kv(key_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[1;32m    643\u001b[0m value_states \u001b[38;5;241m=\u001b[39m repeat_kv(value_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[1;32m    645\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m attention_mask\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:323\u001b[0m, in \u001b[0;36mrepeat_kv\u001b[0;34m(hidden_states, n_rep)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n\u001b[1;32m    322\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, :, :]\u001b[38;5;241m.\u001b[39mexpand(batch, num_key_value_heads, n_rep, slen, head_dim)\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mreshape(batch, num_key_value_heads \u001b[38;5;241m*\u001b[39m n_rep, slen, head_dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "free_cuda()\n",
    "free_cuda()\n",
    "free_cuda()\n",
    "result, code_snippets = main(\"./mutated\", \"HuggingFaceTB/SmolLM-135M-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b96d043e-c0b5-4a38-8636-c53ac550ecba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory freed and garbage collected.\n",
      "CUDA memory freed and garbage collected.\n",
      "CUDA memory freed and garbage collected.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f796873ab1824346ac142a9aa8caf9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for THUDM/codegeex4-all-9b contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/THUDM/codegeex4-all-9b.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Loading THUDM/codegeex4-all-9b requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m free_cuda()\n\u001b[1;32m      3\u001b[0m free_cuda()\n\u001b[0;32m----> 4\u001b[0m result, code_snippets \u001b[38;5;241m=\u001b[39m main(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./mutated\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTHUDM/codegeex4-all-9b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(directory_path, model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(directory_path: \u001b[38;5;28mstr\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     outlines_model \u001b[38;5;241m=\u001b[39m initialize_model(model_name)\n\u001b[1;32m      4\u001b[0m     code_snippets \u001b[38;5;241m=\u001b[39m process_directory(directory_path)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 4-bit quantization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#     bnb_4bit_quant_type=\"nf4\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_map\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# \"quantization_config\": quantization_config,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     }\n\u001b[0;32m---> 17\u001b[0m     llm \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     18\u001b[0m         model_name,\n\u001b[1;32m     19\u001b[0m         token\u001b[38;5;241m=\u001b[39mhf_token,\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Load the tokenizer\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, token\u001b[38;5;241m=\u001b[39mhf_token, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:524\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 524\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    525\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    526\u001b[0m     return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    527\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m    528\u001b[0m     code_revision\u001b[38;5;241m=\u001b[39mcode_revision,\n\u001b[1;32m    529\u001b[0m     _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    532\u001b[0m )\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:979\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    978\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n\u001b[0;32m--> 979\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m resolve_trust_remote_code(\n\u001b[1;32m    980\u001b[0m     trust_remote_code, pretrained_model_name_or_path, has_local_code, has_remote_code\n\u001b[1;32m    981\u001b[0m )\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[1;32m    984\u001b[0m     class_ref \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/dynamic_module_utils.py:640\u001b[0m, in \u001b[0;36mresolve_trust_remote_code\u001b[0;34m(trust_remote_code, model_name, has_local_code, has_remote_code)\u001b[0m\n\u001b[1;32m    637\u001b[0m         _raise_timeout_error(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_local_code \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires you to execute the configuration file in that\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m repo on your local machine. Make sure you have read the code there to avoid malicious use, then\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set the option `trust_remote_code=True` to remove this error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m     )\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trust_remote_code\n",
      "\u001b[0;31mValueError\u001b[0m: Loading THUDM/codegeex4-all-9b requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error."
     ]
    }
   ],
   "source": [
    "free_cuda()\n",
    "free_cuda()\n",
    "free_cuda()\n",
    "result, code_snippets = main(\"./mutated\", \"THUDM/codegeex4-all-9b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d531a405-b6d6-4247-99a5-dbdcde338b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory freed and garbage collected.\n",
      "CUDA memory freed and garbage collected.\n",
      "CUDA memory freed and garbage collected.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191dad40ce2d43ebbfeb9b7d30eb7856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a8959db340463489d2dc79c31b9c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_deepseek.py:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct:\n",
      "- configuration_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c774c773e14b48b5df66631fa05456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_deepseek.py:   0%|          | 0.00/78.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct:\n",
      "- modeling_deepseek.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5520cbcf2924f1f82e601397e5ce9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/480k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3ea07b224e45a1882e4d249de9f193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b05129246a4b648e34cabc2d1e1685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000004.safetensors:   0%|          | 0.00/8.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f3acf0f898489bbdb95e7774d7abae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000004.safetensors:   0%|          | 0.00/8.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m free_cuda()\n\u001b[1;32m      3\u001b[0m free_cuda()\n\u001b[0;32m----> 4\u001b[0m result, code_snippets \u001b[38;5;241m=\u001b[39m main(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./mutated\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(directory_path, model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(directory_path: \u001b[38;5;28mstr\u001b[39m, model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     outlines_model \u001b[38;5;241m=\u001b[39m initialize_model(model_name)\n\u001b[1;32m      4\u001b[0m     code_snippets \u001b[38;5;241m=\u001b[39m process_directory(directory_path)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36minitialize_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 4-bit quantization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#     bnb_4bit_quant_type=\"nf4\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_map\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_attentions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# \"quantization_config\": quantization_config,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     }\n\u001b[0;32m---> 17\u001b[0m     llm \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     18\u001b[0m         model_name,\n\u001b[1;32m     19\u001b[0m         token\u001b[38;5;241m=\u001b[39mhf_token,\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Load the tokenizer\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, token\u001b[38;5;241m=\u001b[39mhf_token, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:559\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    560\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    561\u001b[0m     )\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/modeling_utils.py:3715\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3714\u001b[0m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3715\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   3716\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3717\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3718\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   3719\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   3720\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   3721\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   3722\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   3723\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   3724\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   3725\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   3726\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   3727\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m   3728\u001b[0m     )\n\u001b[1;32m   3730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3731\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3732\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   3733\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3734\u001b[0m ):\n\u001b[1;32m   3735\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py:1079\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1079\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   1080\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   1081\u001b[0m             shard_filename,\n\u001b[1;32m   1082\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1083\u001b[0m             force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1084\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1085\u001b[0m             resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   1086\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1087\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1088\u001b[0m             user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   1089\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1090\u001b[0m             subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   1091\u001b[0m             _commit_hash\u001b[38;5;241m=\u001b[39m_commit_hash,\n\u001b[1;32m   1092\u001b[0m         )\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    403\u001b[0m         path_or_repo_id,\n\u001b[1;32m    404\u001b[0m         filename,\n\u001b[1;32m    405\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    406\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    407\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    408\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    409\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    410\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    411\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    412\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    413\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    414\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    415\u001b[0m     )\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m   1203\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1219\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1222\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1223\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1224\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m   1225\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   1226\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1227\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   1228\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1231\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1232\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1233\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m   1234\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1236\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1237\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1367\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1365\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1367\u001b[0m     _download_to_tmp_and_move(\n\u001b[1;32m   1368\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mPath(blob_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.incomplete\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1369\u001b[0m         destination_path\u001b[38;5;241m=\u001b[39mPath(blob_path),\n\u001b[1;32m   1370\u001b[0m         url_to_download\u001b[38;5;241m=\u001b[39murl_to_download,\n\u001b[1;32m   1371\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1372\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1373\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1374\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1375\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1376\u001b[0m     )\n\u001b[1;32m   1377\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1884\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1881\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1882\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1884\u001b[0m     http_get(\n\u001b[1;32m   1885\u001b[0m         url_to_download,\n\u001b[1;32m   1886\u001b[0m         f,\n\u001b[1;32m   1887\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1888\u001b[0m         resume_size\u001b[38;5;241m=\u001b[39mresume_size,\n\u001b[1;32m   1889\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1890\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1891\u001b[0m     )\n\u001b[1;32m   1893\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1894\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:539\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    537\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(amt\u001b[38;5;241m=\u001b[39mamt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_read(amt)\n\u001b[1;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt, read1\u001b[38;5;241m=\u001b[39mread1) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "free_cuda()\n",
    "free_cuda()\n",
    "free_cuda()\n",
    "result, code_snippets = main(\"./mutated\", \"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ded23-f0a7-4b63-86cc-40d13cb97c02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
